{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Emotion Classification with BERT-based Models\n",
    "\n",
    "This notebook reproduces the results for **Project 2: Emotion Classification**.\n",
    "It covers setup, downloading pre-trained weights, training, evaluation, and compression benchmarks.\n",
    "\n",
    "### âš ï¸ Hardware Requirement: GPU Required\n",
    "**Please ensure you are connected to a GPU Runtime.**\n",
    "- Go to `Runtime` > `Change runtime type` > `Hardware accelerator` > Select **T4 GPU** (or A100/V100).\n",
    "- **Do NOT use TPU**: The compression library `bitsandbytes` (used for 4-bit quantization) currently relies on CUDA kernels and is not compatible with Colab TPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clone the repository\n",
    "!git clone https://github.com/Roeyx/NLP.git\n",
    "\n",
    "# 2. Enter the project directory\n",
    "%cd NLP/Project2\n",
    "\n",
    "# 3. Install dependencies\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# 4. Create outputs directory\n",
    "!mkdir -p outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Pre-trained Weights\n",
    "We download the trained checkpoints to skip the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Best Original Model (CardiffRoBERTa - FP32)\n",
    "!gdown 1hU4AA1mIE6fJHYEYUB0lgwBnyiESjoFK -O outputs/best_CardiffRoBERTa.pt\n",
    "\n",
    "# Download Best Compressed Model (Quantized NF4)\n",
    "!gdown 1bYhpRRKBpJu3RNcOG753ss4SMXMeqwPA -O outputs/best_CardiffRoBERTa_quantized_nf4.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Demo\n",
    "Train a fresh model from scratch (using ModernBERT for efficiency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python emotion_classifier.py --mode train --model ModernBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation (Reproduce Results)\n",
    "Evaluate the downloaded models on the validation set to verify Accuracy and F1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Evaluating Original Model (FP32) ===\")\n",
    "!python emotion_classifier.py --mode evaluate --weights outputs/best_CardiffRoBERTa.pt --val validation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Evaluating Compressed Model (Quantized NF4) ===\")\n",
    "!python emotion_classifier.py --mode evaluate --weights outputs/best_CardiffRoBERTa_quantized_nf4.pt --val validation.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference on Custom Test Data\n",
    "Upload your own `test.csv` file (must contain a 'text' column) to generate predictions.\n",
    "\n",
    "**Note:**\n",
    "- Predictions will be saved to `<filename>_predictions.csv`.\n",
    "- The file contains the original text plus `predicted_label` (0-5) and `predicted_emotion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"Please upload your test.csv file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "filename = list(uploaded.keys())[0]\n",
    "print(f\"Uploaded: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference using the Best Original Model\n",
    "!python emotion_classifier.py --mode inference --weights outputs/best_CardiffRoBERTa.pt --test_csv \"{filename}\"\n",
    "\n",
    "output_file = f\"{os.path.splitext(filename)[0]}_predictions.csv\"\n",
    "print(f\"\\nâœ… Predictions saved to: {output_file}\")\n",
    "\n",
    "# Display first few predictions\n",
    "!head -n 5 \"{output_file}\"\n",
    "\n",
    "# Download the results\n",
    "files.download(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compression Analysis\n",
    "Run the full compression benchmark suite (Pruning, INT8, NF4, Combined) to generate the comparison report.\n",
    "\n",
    "**Note:** This step requires the GPU runtime for `bitsandbytes` quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python emotion_classifier.py --mode compress --weights outputs/best_CardiffRoBERTa.pt --val validation.csv"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
